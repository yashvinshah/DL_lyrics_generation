{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yh5vCGxY6xOP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_32832\\1277796319.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import nltk\n",
        "import re\n",
        "import keras\n",
        "import random\n",
        "import io\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Embedding, Bidirectional  # Import Embedding layer\n",
        "from keras.optimizers import Adamax\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPny_SVU7BHd",
        "outputId": "6118bb89-1261-48eb-a7cb-13325a916ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load LSTM data\n",
        "df_lstm = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DL_mp/data/lyrics-data.csv\")\n",
        "df_lstm.drop(['ALink','SName','SLink'],axis=1,inplace=True)\n",
        "df_lstm = df_lstm[:700]\n",
        "\n",
        "# Load RNN data\n",
        "df_rnn = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DL_mp/data/Songs.csv\")\n",
        "df_rnn.drop(['Artist'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YRsnkuqM7JRG"
      },
      "outputs": [],
      "source": [
        "# Define LSTM model\n",
        "def lstm_model(df):\n",
        "    # Preprocessing\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(df['Lyric'].astype(str).str.lower())\n",
        "    total_words = len(tokenizer.word_index)+1\n",
        "    tokenized_sentences = tokenizer.texts_to_sequences(df['Lyric'].astype(str))\n",
        "\n",
        "    # Slash sequences into n gram sequence\n",
        "    input_sequences = []\n",
        "    for i in tokenized_sentences:\n",
        "        for t in range(1, len(i)):\n",
        "            n_gram_sequence = i[:t+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "\n",
        "    # Pre-padding\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "    # Create predictors and label\n",
        "    X, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    y = to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "    # Create model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 40, input_length=max_sequence_len-1))\n",
        "    model.add(Bidirectional(LSTM(250)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(X, y, epochs=10, verbose=1)\n",
        "\n",
        "    return model, tokenizer, max_sequence_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z71__B7T7zWl"
      },
      "outputs": [],
      "source": [
        "# Define RNN model\n",
        "def rnn_model(df):\n",
        "    # Preprocessing\n",
        "    Corpus = ''.join(df['Lyrics']).lower()\n",
        "    to_remove = ['{', '}', '~', '©', 'à', 'á', 'ã', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'ñ', 'ó', 'ö', 'ü', 'ŏ',\n",
        "                 'е', 'ا', 'س', 'ل', 'م', 'و', '\\u2005', '\\u200a', '\\u200b', '–', '—', '‘', '’', '‚', '“', '”',\n",
        "                 '…', '\\u205f', '\\ufeff', '!', '&', '(', ')', '*', '-',  '/', ]\n",
        "    for symbol in to_remove:\n",
        "        Corpus = Corpus.replace(symbol, \" \")\n",
        "\n",
        "    symb = sorted(list(set(Corpus)))\n",
        "    mapping = dict((c, i) for i, c in enumerate(symb))\n",
        "    reverse_mapping = dict((i, c) for i, c in enumerate(symb))\n",
        "\n",
        "    # Splitting the Corpus\n",
        "    length = 40\n",
        "    features, targets = [], []\n",
        "    for i in range(0, len(Corpus) - length, 1):\n",
        "        feature = Corpus[i:i + length]\n",
        "        target = Corpus[i + length]\n",
        "        features.append([mapping[j] for j in feature])\n",
        "        targets.append(mapping[target])\n",
        "\n",
        "    X = (np.reshape(features, (len(features), length, 1)))/ float(len(symb))\n",
        "    y = to_categorical(targets)\n",
        "\n",
        "    # Create RNN model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "    model.add(Dense(y.shape[1], activation='softmax'))\n",
        "    opt = Adamax(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "    # Train RNN model\n",
        "    history = model.fit(X, y, batch_size=128, epochs=10)\n",
        "\n",
        "    return model, reverse_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q0sMhAlM74mW"
      },
      "outputs": [],
      "source": [
        "# Generate lyrics from LSTM model\n",
        "def generate_lyrics_lstm(seed_text, model, tokenizer, max_sequence_len, length):\n",
        "    completed_song = seed_text\n",
        "    for _ in range(length):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_index = np.argmax(predicted)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "        completed_song += \" \" + output_word\n",
        "    return completed_song"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RZh4bEa0779x"
      },
      "outputs": [],
      "source": [
        "# Generate lyrics from RNN model\n",
        "def generate_lyrics_rnn(seed_text, model, reverse_mapping, length):\n",
        "    generated= \"\"\n",
        "    starter = seed_text\n",
        "    seed = [mapping[char] for char in starter]\n",
        "    generated += starter\n",
        "    for i in range(length):\n",
        "        seed = [mapping[char] for char in starter]\n",
        "        x_pred = np.reshape(seed, (1, len(seed), 1))\n",
        "        x_pred = x_pred/ float(len(symb))\n",
        "        prediction = model.predict(x_pred, verbose=0)[0]\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction) / 1.0\n",
        "        exp_preds = np.exp(prediction)\n",
        "        prediction = exp_preds / np.sum(exp_preds)\n",
        "        probas = np.random.multinomial(1, prediction, 1)\n",
        "        index = np.argmax(prediction)\n",
        "        next_char = reverse_mapping[index]\n",
        "        generated += next_char\n",
        "        starter = starter[1:] + next_char\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DtBKMST7_15",
        "outputId": "32119f76-e6e9-4f20-dff9-a13069bcfb84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3121/3121 [==============================] - 273s 84ms/step - loss: 6.6072 - accuracy: 0.0343\n",
            "Epoch 2/10\n",
            "3121/3121 [==============================] - 197s 63ms/step - loss: 5.6460 - accuracy: 0.0941\n",
            "Epoch 3/10\n",
            "3121/3121 [==============================] - 195s 62ms/step - loss: 4.8801 - accuracy: 0.1575\n",
            "Epoch 4/10\n",
            "3121/3121 [==============================] - 192s 62ms/step - loss: 4.1856 - accuracy: 0.2285\n",
            "Epoch 5/10\n",
            "3121/3121 [==============================] - 192s 62ms/step - loss: 3.5996 - accuracy: 0.3021\n",
            "Epoch 6/10\n",
            "3121/3121 [==============================] - 192s 62ms/step - loss: 3.1207 - accuracy: 0.3671\n",
            "Epoch 7/10\n",
            "3121/3121 [==============================] - 191s 61ms/step - loss: 2.7395 - accuracy: 0.4267\n",
            "Epoch 8/10\n",
            "3121/3121 [==============================] - 191s 61ms/step - loss: 2.4271 - accuracy: 0.4820\n",
            "Epoch 9/10\n",
            "3121/3121 [==============================] - 191s 61ms/step - loss: 2.1736 - accuracy: 0.5254\n",
            "Epoch 10/10\n",
            "3121/3121 [==============================] - 192s 61ms/step - loss: 1.9674 - accuracy: 0.5658\n",
            "Epoch 1/10\n",
            "8168/8168 [==============================] - 59s 7ms/step - loss: 2.6004\n",
            "Epoch 2/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 2.3173\n",
            "Epoch 3/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 2.1435\n",
            "Epoch 4/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 2.0210\n",
            "Epoch 5/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 1.9257\n",
            "Epoch 6/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 1.8603\n",
            "Epoch 7/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 1.8266\n",
            "Epoch 8/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 1.7932\n",
            "Epoch 9/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 1.7599\n",
            "Epoch 10/10\n",
            "8168/8168 [==============================] - 57s 7ms/step - loss: 1.7307\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# Define input text\n",
        "input_text = \"the sky is blue\"\n",
        "\n",
        "# Train LSTM model\n",
        "lstm_model, lstm_tokenizer, lstm_max_sequence_len = lstm_model(df_lstm)\n",
        "\n",
        "# Train RNN model\n",
        "rnn_model, reverse_mapping = rnn_model(df_rnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "k_o25Oz1JXNa",
        "outputId": "ff9df7fb-7f3f-4ea9-9d23-08f044fe1ecb"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 584), found shape=(None, 585)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0fe4408f6a82>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate lyrics from LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerated_lyrics_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_lyrics_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_max_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m140\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_lyrics_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate lyrics from RNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0263e819964e>\u001b[0m in \u001b[0;36mgenerate_lyrics_lstm\u001b[0;34m(seed_text, model, tokenizer, max_sequence_len, length)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpredicted_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 584), found shape=(None, 585)\n"
          ]
        }
      ],
      "source": [
        "# Generate lyrics from LSTM model\n",
        "generated_lyrics_lstm = generate_lyrics_lstm(input_text, lstm_model, lstm_tokenizer, lstm_max_sequence_len, 140)\n",
        "print(generated_lyrics_lstm)\n",
        "\n",
        "# Generate lyrics from RNN model\n",
        "generated_lyrics_rnn = generate_lyrics_rnn(input_text, rnn_model, reverse_mapping, 140)\n",
        "print(generated_lyrics_rnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jvTPJzb8Pu_"
      },
      "outputs": [],
      "source": [
        "# Calculate MSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_score = mean_squared_error(generated_lyrics_lstm, generated_lyrics_rnn)\n",
        "print(\"MSE Score:\", mse_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z-Ys4Fs883R"
      },
      "outputs": [],
      "source": [
        "# Plot graphical representation\n",
        "plt.plot(generated_lyrics_lstm, label='LSTM')\n",
        "plt.plot(generated_lyrics_rnn, label='RNN')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Lyrics')\n",
        "plt.title('Comparison of LSTM and RNN Generated Lyrics')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
